# ğŸ§  Deep Learning Experiments â€” USP Specialization

Experimentos em Aprendizado Profundo e MÃ©todos ClÃ¡ssicos
EspecializaÃ§Ã£o â€“ Universidade de SÃ£o Paulo (USP)

Este repositÃ³rio reÃºne uma sÃ©rie de cinco experimentos prÃ¡ticos desenvolvidos no contexto da disciplina Experimentos com Aprendizado Profundo e MÃ©todos ClÃ¡ssicos, pertencente a uma especializaÃ§Ã£o na Universidade de SÃ£o Paulo (USP).

O objetivo principal foi explorar, comparar e integrar tÃ©cnicas modernas de Deep Learning com mÃ©todos clÃ¡ssicos de Machine Learning, avaliando desempenho, generalizaÃ§Ã£o, compressÃ£o de dados e reutilizaÃ§Ã£o de representaÃ§Ãµes profundas.

# ğŸ“Œ VisÃ£o Geral dos Experimentos
## ğŸ”¹ Experimento 1 â€” CNNs BÃ¡sicas para ClassificaÃ§Ã£o

#Objetivo:
## Avaliar o desempenho de uma CNN simples em um problema de classificaÃ§Ã£o supervisionada.

##O que foi feito:

Treinamento de CNN em dados reais

AvaliaÃ§Ã£o de acurÃ¡cia e matriz de confusÃ£o

Estabelecimento de baseline para os experimentos seguintes

## ğŸ”¹ Experimento 2 â€” GeraÃ§Ã£o de Dados com GANs Condicionais

## Objetivo:
Gerar dados sintÃ©ticos condicionais e avaliar seu impacto no treinamento de classificadores.

O que foi feito:

Treinamento de GAN condicional

GeraÃ§Ã£o de amostras sintÃ©ticas

Treinamento de CNN com dados reais e sintÃ©ticos

ComparaÃ§Ã£o com treinamento apenas em dados reais

## ğŸ”¹ Experimento 3 â€” Autoencoders Adversariais (CAAE)

## Objetivo:
Explorar Autoencoders Adversariais como alternativa conceitual Ã s GANs para geraÃ§Ã£o de dados.

O que foi feito:

Treinamento de um Conditional Adversarial Autoencoder (CAAE)

VariaÃ§Ã£o da dimensÃ£o do espaÃ§o latente

Mistura de dados reais e sintÃ©ticos no treinamento

AvaliaÃ§Ã£o da mÃ©trica FID

ComparaÃ§Ã£o de desempenho da CNN:

com dados reais

com dados sintÃ©ticos

com dados mistos

DeterminaÃ§Ã£o da proporÃ§Ã£o ideal de dados sintÃ©ticos

# ğŸ“Œ ConclusÃ£o:
O uso controlado de dados sintÃ©ticos melhora o desempenho, desde que nÃ£o sejam utilizados no conjunto de teste.

## ğŸ”¹ Experimento 4 â€” Features Profundas + MÃ©todos ClÃ¡ssicos

## Objetivo:
Reutilizar representaÃ§Ãµes profundas como atributos de alto nÃ­vel para mÃ©todos clÃ¡ssicos.

O que foi feito:

Treinamento de CNN para extraÃ§Ã£o de features

Treinamento de ensembles globais (MLP e SVM)

AplicaÃ§Ã£o de Mapas Auto-OrganizÃ¡veis (SOM)

AnÃ¡lise da pureza dos clusters

Treinamento de classificadores locais (especialistas) por cluster

ComparaÃ§Ã£o entre:

Ensembles globais

Especialistas locais via SOM

# ğŸ“Œ ConclusÃ£o:
Especialistas locais podem superar modelos globais em regiÃµes especÃ­ficas do espaÃ§o de caracterÃ­sticas.

##ğŸ”¹ Experimento 5 â€” CompressÃ£o e ReduÃ§Ã£o Dimensional com Autoencoders

Objetivo:
Analisar compressÃ£o de dados e preservaÃ§Ã£o de informaÃ§Ã£o relevante.

O que foi feito:

Treinamento de Autoencoder nÃ£o supervisionado

VariaÃ§Ã£o da dimensÃ£o latente (16, 32, 64, 128)

ExtraÃ§Ã£o do espaÃ§o latente

Treinamento de MLP e SVM sobre o espaÃ§o comprimido

ComparaÃ§Ã£o com features profundas extraÃ­das de CNN

AnÃ¡lise do trade-off compressÃ£o Ã— desempenho

# ğŸ“Œ ConclusÃ£o:
DimensÃµes latentes intermediÃ¡rias oferecem o melhor equilÃ­brio entre compressÃ£o e desempenho preditivo.

# ğŸ“Š ConclusÃµes Gerais

RepresentaÃ§Ãµes profundas podem ser reutilizadas com sucesso por mÃ©todos clÃ¡ssicos

Dados sintÃ©ticos podem melhorar generalizaÃ§Ã£o, quando usados corretamente

Autoencoders permitem reduÃ§Ã£o dimensional eficiente, preservando informaÃ§Ã£o relevante

A combinaÃ§Ã£o de Deep Learning + mÃ©todos clÃ¡ssicos resulta em modelos mais flexÃ­veis e interpretÃ¡veis

TÃ©cnicas de especializaÃ§Ã£o local (SOM + especialistas) sÃ£o eficazes em cenÃ¡rios complexos

## ğŸ› ï¸ Tecnologias e Stack Utilizadas
## ğŸ”§ Linguagem

- Python 3

## ğŸ§  Deep Learning

- PyTorch

- Torchvision

## ğŸ“Š Machine Learning ClÃ¡ssico

- Scikit-learn

- SVM

- MLP

- MÃ©tricas de avaliaÃ§Ã£o

## ğŸ“ˆ VisualizaÃ§Ã£o

- Matplotlib

## ğŸ—‚ï¸ Outros

- NumPy

- Jupyter / Scripts Python

- Git & GitHub

## ğŸ“ Contexto AcadÃªmico

Este projeto foi desenvolvido como parte da EspecializaÃ§Ã£o na Universidade de SÃ£o Paulo (USP), na disciplina:

Experimentos com Aprendizado Profundo e MÃ©todos ClÃ¡ssicos

## ğŸ‘¨â€ğŸ’» Autor

Fabiano Henrique
Computer Science Student & AI/ML Student
EspecializaÃ§Ã£o em andamento â€” USP (Universidade de Sao Paulo)
