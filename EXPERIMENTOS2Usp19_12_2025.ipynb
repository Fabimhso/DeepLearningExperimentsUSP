{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experimento 2\n",
        "\n",
        "cGANS-MLP"
      ],
      "metadata": {
        "id": "UCQv0llg6YW0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "SIXVPB1Ap5VH",
        "outputId": "9279a9b0-21c7-4f32-b181-c0e77127a877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CNN BASELINE (DADOS REAIS) ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3529491608.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mcnn_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m plot_confusion(cnn_real, test_loader, device,\n\u001b[1;32m     67\u001b[0m                \"CNN treinada apenas com dados reais\")\n",
            "\u001b[0;32m/content/training.py\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, loader, device, epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# Atualiza pesos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# main_experimento2.py\n",
        "# Experimento 2 — cGAN MLP\n",
        "# 1) Treina CNN com dados reais (baseline)\n",
        "# 2) Treina cGAN MLP com dados reais\n",
        "# 3) Gera dados sintéticos por proporção\n",
        "# 4) Mistura dados reais + sintéticos\n",
        "# 5) Treina CNN do zero\n",
        "# 6) Avalia CNN apenas com dados reais\n",
        "# 7) Calcula FID\n",
        "# =========================================================\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "# Modelos\n",
        "from models import (\n",
        "    CNNClassifier,\n",
        "    ConditionalGenerator,\n",
        "    ConditionalDiscriminator\n",
        ")\n",
        "\n",
        "# Rotinas\n",
        "from training import (\n",
        "    train_classifier,\n",
        "    train_cgan,\n",
        "    plot_confusion,\n",
        "    compute_statistics,\n",
        "    calculate_fid\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# CONFIGURAÇÃO\n",
        "# =========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# =========================================================\n",
        "# DATASET MNIST\n",
        "# =========================================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    \"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    \"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# =========================================================\n",
        "# BASELINE — CNN COM DADOS REAIS\n",
        "# =========================================================\n",
        "print(\"\\n=== CNN BASELINE (DADOS REAIS) ===\")\n",
        "\n",
        "cnn_real = CNNClassifier().to(device)\n",
        "train_classifier(cnn_real, train_loader, device)\n",
        "plot_confusion(cnn_real, test_loader, device,\n",
        "               \"CNN treinada apenas com dados reais\")\n",
        "\n",
        "# =========================================================\n",
        "# TREINAMENTO DA cGAN MLP\n",
        "# =========================================================\n",
        "print(\"\\n=== TREINAMENTO DA cGAN MLP ===\")\n",
        "\n",
        "G = ConditionalGenerator().to(device)\n",
        "D = ConditionalDiscriminator().to(device)\n",
        "\n",
        "train_cgan(G, D, train_loader, device, epochs=50)\n",
        "\n",
        "# =========================================================\n",
        "# FUNÇÃO PARA GERAR DADOS SINTÉTICOS POR PROPORÇÃO\n",
        "# =========================================================\n",
        "def generate_fake_dataset_by_ratio(G, ratio, device):\n",
        "    \"\"\"\n",
        "    Gera dados sintéticos balanceados por classe\n",
        "    \"\"\"\n",
        "    n_real = len(train_dataset)\n",
        "    n_fake = int(n_real * ratio)\n",
        "    n_per_class = n_fake // 10\n",
        "\n",
        "    images, labels = [], []\n",
        "\n",
        "    G.eval()\n",
        "    with torch.no_grad():\n",
        "        for cls in range(10):\n",
        "            z = torch.randn(n_per_class, 100, device=device)\n",
        "            y = torch.full((n_per_class,), cls, device=device, dtype=torch.long)\n",
        "            x_fake = G(z, y).cpu()\n",
        "            images.append(x_fake)\n",
        "            labels.append(y.cpu())\n",
        "\n",
        "    images = torch.cat(images)\n",
        "    labels = torch.cat(labels)\n",
        "\n",
        "    return TensorDataset(images, labels)\n",
        "\n",
        "# =========================================================\n",
        "# FID — REAL x FAKE\n",
        "# =========================================================\n",
        "print(\"\\n=== FID (REAL x FAKE) ===\")\n",
        "\n",
        "feature_extractor = cnn_real.features\n",
        "\n",
        "mu_real, sigma_real = compute_statistics(\n",
        "    train_loader, feature_extractor, device\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# LOOP DAS PROPORÇÕES\n",
        "# =========================================================\n",
        "ratios = [0.1, 0.3, 0.5]\n",
        "\n",
        "for ratio in ratios:\n",
        "\n",
        "    print(f\"\\n=== PROPORÇÃO DE DADOS SINTÉTICOS: {int(ratio*100)}% ===\")\n",
        "\n",
        "    # Gera dados fake\n",
        "    fake_dataset = generate_fake_dataset_by_ratio(G, ratio, device)\n",
        "    fake_loader = DataLoader(fake_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # Calcula FID\n",
        "    mu_fake, sigma_fake = compute_statistics(\n",
        "        fake_loader, feature_extractor, device\n",
        "    )\n",
        "\n",
        "    fid_value = calculate_fid(\n",
        "        mu_real, sigma_real, mu_fake, sigma_fake\n",
        "    )\n",
        "\n",
        "    print(f\"FID (Real vs Fake {int(ratio*100)}%): {fid_value:.2f}\")\n",
        "\n",
        "    # Mistura dados reais + sintéticos\n",
        "    mixed_dataset = ConcatDataset([train_dataset, fake_dataset])\n",
        "    mixed_loader = DataLoader(\n",
        "        mixed_dataset, batch_size=128, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Treina CNN do zero\n",
        "    cnn_mixed = CNNClassifier().to(device)\n",
        "    train_classifier(cnn_mixed, mixed_loader, device)\n",
        "\n",
        "    # Avaliação apenas com dados reais\n",
        "    plot_confusion(\n",
        "        cnn_mixed,\n",
        "        test_loader,\n",
        "        device,\n",
        "        f\"CNN com {int(ratio*100)}% dados sintéticos\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# models.py\n",
        "# Contém apenas definições de ARQUITETURA CNN e cGANs\n",
        "# Para cGANS utiliza uma MLP\n",
        "# (nenhum treinamento aqui)\n",
        "# =========================================================\n",
        "\n",
        "# Importa o PyTorch base\n",
        "import torch\n",
        "\n",
        "# Importa o módulo de redes neurais\n",
        "import torch.nn as nn\n",
        "\n",
        "# =========================================================\n",
        "# CNN CLASSIFICADORA PARA MNIST\n",
        "# =========================================================\n",
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN simples usada para:\n",
        "    - Classificação com dados reais\n",
        "    - Classificação com dados fake gerados pela cGAN\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Inicializa a classe base nn.Module\n",
        "        super().__init__()\n",
        "\n",
        "        # -------------------------\n",
        "        # Extrator de características\n",
        "        # -------------------------\n",
        "        self.features = nn.Sequential(\n",
        "\n",
        "            # Primeira convolução:\n",
        "            # Entrada: 1 canal (imagem MNIST)\n",
        "            # Saída: 32 mapas de características\n",
        "            # kernel 3x3\n",
        "            # Paramentros: numero de filtros=32, tamanho do kernel = 3\n",
        "            nn.Conv2d(1, 32, kernel_size=3),\n",
        "\n",
        "            # Função de ativação ReLU\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Reduz resolução espacial pela metade\n",
        "            nn.MaxPool2d(2),\n",
        "            #saida mapa 13x33\n",
        "\n",
        "            # Segunda convolução:\n",
        "            # Entrada: 32 mapas\n",
        "            # Saída: 64 mapas\n",
        "            nn.Conv2d(32, 64, kernel_size=3),\n",
        "\n",
        "            # Ativação\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Novo downsampling\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        # saida mapa 5x5\n",
        "\n",
        "        # -------------------------\n",
        "        # Classificador totalmente conectado\n",
        "        # -------------------------\n",
        "        self.classifier = nn.Sequential(\n",
        "\n",
        "            # Achata o tensor 4D → 2D\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Camada totalmente conectada\n",
        "            nn.Linear(64 * 5 * 5, 128),\n",
        "\n",
        "            # Ativação\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Camada de saída (10 classes)\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo forward da CNN\n",
        "        \"\"\"\n",
        "\n",
        "        # Extrai características\n",
        "        x = self.features(x)\n",
        "\n",
        "        # Realiza tarefa de Classificação\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# GERADOR CONDICIONAL (cGAN)\n",
        "# =========================================================\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    Gerador da cGAN:\n",
        "    Entrada:\n",
        "      - vetor de ruído z\n",
        "      - rótulo y\n",
        "    Saída:\n",
        "      - imagem 28x28 condicionada ao rótulo\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, z_dim=100, n_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding transforma rótulos em vetores\n",
        "        self.label_emb = nn.Embedding(\n",
        "            num_embeddings=n_classes,\n",
        "            embedding_dim=n_classes\n",
        "        )\n",
        "\n",
        "        # Rede totalmente conectada (MLP)\n",
        "        self.net = nn.Sequential(\n",
        "\n",
        "            # Entrada: ruído + rótulo\n",
        "            nn.Linear(z_dim + n_classes, 256),\n",
        "\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Saída: 28*28 pixels\n",
        "            nn.Linear(512, 784),\n",
        "\n",
        "            # Tanh → compatível com normalização [-1, 1]\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, y):\n",
        "        \"\"\"\n",
        "        Forward do gerador\n",
        "        \"\"\"\n",
        "\n",
        "        # Converte rótulo inteiro em vetor embedding\n",
        "        y_emb = self.label_emb(y)\n",
        "\n",
        "        # Concatena ruído e rótulo\n",
        "        x = torch.cat([z, y_emb], dim=1)\n",
        "\n",
        "        # Gera imagem e reorganiza para formato 2D\n",
        "        img = self.net(x).view(-1, 1, 28, 28)\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# DISCRIMINADOR CONDICIONAL (cGAN)\n",
        "# =========================================================\n",
        "class ConditionalDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminador da cGAN:\n",
        "    Entrada:\n",
        "      - imagem\n",
        "      - rótulo\n",
        "    Saída:\n",
        "      - probabilidade de ser real\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding do rótulo no espaço da imagem\n",
        "        self.label_emb = nn.Embedding(\n",
        "            num_embeddings=n_classes,\n",
        "            embedding_dim=784\n",
        "        )\n",
        "\n",
        "        # Rede discriminadora - MLP\n",
        "        self.net = nn.Sequential(\n",
        "\n",
        "            nn.Linear(784 * 2, 512), #tamanho da imagem x (dados + classe)\n",
        "                                      #vetor de classe codificado como 784 valores\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "\n",
        "            # Saída probabilística\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        Forward do discriminador\n",
        "        \"\"\"\n",
        "\n",
        "        # Achata imagem\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Embedding do rótulo\n",
        "        y_emb = self.label_emb(y)\n",
        "\n",
        "        # Concatena imagem + rótulo\n",
        "        d_input = torch.cat([x, y_emb], dim=1)\n",
        "\n",
        "        # Classificação real/fake\n",
        "        out = self.net(d_input)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "RWgTZsfLqDKi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# training.py\n",
        "# Contém rotinas de treinamento e métricas\n",
        "# =========================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from scipy import linalg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# TREINAMENTO DA CNN\n",
        "# =========================================================\n",
        "def train_classifier(model, loader, device, epochs=5):\n",
        "    \"\"\"\n",
        "    Treina uma CNN supervisionada\n",
        "    \"\"\"\n",
        "\n",
        "    # Coloca o modelo em modo treino\n",
        "    model.train()\n",
        "\n",
        "    # Otimizador Adam\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Função de perda multiclasse\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Loop de épocas\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Loop sobre batches\n",
        "        for x, y in loader:\n",
        "\n",
        "            # Move dados para GPU/CPU\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            # Zera gradientes acumulados\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(x)\n",
        "\n",
        "            # Calcula perda\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Atualiza pesos\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"[CNN] Epoch {epoch+1}/{epochs} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# MATRIZ DE CONFUSÃO\n",
        "# =========================================================\n",
        "def plot_confusion(model, loader, device, title):\n",
        "    \"\"\"\n",
        "    Calcula e plota a matriz de confusão\n",
        "    \"\"\"\n",
        "\n",
        "    # Modo avaliação\n",
        "    model.eval()\n",
        "\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    # Sem gradientes\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            # Predição\n",
        "            preds = model(x).argmax(dim=1).cpu()\n",
        "\n",
        "            y_true.extend(y.numpy())\n",
        "            y_pred.extend(preds.numpy())\n",
        "\n",
        "    # Matriz de confusão\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Visualização\n",
        "    ConfusionMatrixDisplay(cm).plot()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# TREINAMENTO DA cGAN\n",
        "# =========================================================\n",
        "def train_cgan(G, D, loader, device, epochs=20, z_dim=100):\n",
        "    \"\"\"\n",
        "    Treina uma cGAN (gerador + discriminador)\n",
        "    \"\"\"\n",
        "\n",
        "    # Otimizadores\n",
        "    opt_g = optim.Adam(G.parameters(), lr=2e-4)\n",
        "    opt_d = optim.Adam(D.parameters(), lr=2e-4)\n",
        "\n",
        "    # Perda adversarial\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in loader:\n",
        "\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            batch = x.size(0)\n",
        "\n",
        "            # ======================\n",
        "            # Treina Discriminador\n",
        "            # ======================\n",
        "            z = torch.randn(batch, z_dim, device=device)\n",
        "\n",
        "            fake = G(z, y)\n",
        "\n",
        "            loss_d = (\n",
        "                criterion(D(x, y), torch.ones(batch, 1, device=device)) +\n",
        "                criterion(D(fake.detach(), y),\n",
        "                          torch.zeros(batch, 1, device=device))\n",
        "            )\n",
        "\n",
        "            opt_d.zero_grad()\n",
        "            loss_d.backward()\n",
        "            opt_d.step()\n",
        "\n",
        "            # ======================\n",
        "            # Treina Gerador\n",
        "            # ======================\n",
        "            z = torch.randn(batch, z_dim, device=device)\n",
        "\n",
        "            fake = G(z, y)\n",
        "\n",
        "            loss_g = criterion(\n",
        "                D(fake, y),\n",
        "                torch.ones(batch, 1, device=device)\n",
        "            )\n",
        "\n",
        "            opt_g.zero_grad()\n",
        "            loss_g.backward()\n",
        "            opt_g.step()\n",
        "\n",
        "        print(f\"[cGAN] Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"D: {loss_d.item():.4f} | G: {loss_g.item():.4f}\")\n",
        "\n",
        "\n",
        "# =========================================================\n",
        "# FID\n",
        "# =========================================================\n",
        "def compute_statistics(loader, extractor, device):\n",
        "    \"\"\"\n",
        "    Calcula média e covariância das features\n",
        "    \"\"\"\n",
        "\n",
        "    features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(device)\n",
        "            features.append(extractor(x).cpu().numpy())\n",
        "\n",
        "    features = np.concatenate(features)\n",
        "\n",
        "    return np.mean(features, axis=0), np.cov(features, rowvar=False)\n",
        "\n",
        "\n",
        "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
        "    \"\"\"\n",
        "    Calcula Fréchet Inception Distance\n",
        "    \"\"\"\n",
        "    diff = mu1 - mu2\n",
        "    covmean = linalg.sqrtm(sigma1 @ sigma2)\n",
        "\n",
        "\n",
        "\n",
        "    # Correção numérica (parte imaginária pequena)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "\n",
        "    return fid"
      ],
      "metadata": {
        "id": "E78sFwk4qIdN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cGANS-CONV"
      ],
      "metadata": {
        "id": "Ci69kufzHCph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# main_experimento2.py\n",
        "# Experimento 2 — cGAN Convolucional (DC-cGAN)\n",
        "# =========================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
        "\n",
        "# ======================\n",
        "# Importação dos módulos\n",
        "# ======================\n",
        "\n",
        "# Executado a partir das celulas abaixo no colab.\n",
        "\n",
        "# ======================\n",
        "# Configurações\n",
        "# ======================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.manual_seed(42)\n",
        "\n",
        "batch_size = 128\n",
        "z_dim = 100\n",
        "ratios = [0.1, 0.3, 0.5]\n",
        "\n",
        "print(f\"Dispositivo: {device}\")\n",
        "\n",
        "# ======================\n",
        "# Transformações\n",
        "# ======================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# ======================\n",
        "# Dataset MNIST\n",
        "# ======================\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"data\", train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# CNN BASELINE — DADOS REAIS\n",
        "# =========================================================\n",
        "print(\"\\n=== CNN BASELINE (DADOS REAIS) ===\")\n",
        "\n",
        "cnn_real = CNNClassifier().to(device)\n",
        "train_cnn(cnn_real, train_loader, device, epochs=10)\n",
        "\n",
        "plot_confusion_matrix(\n",
        "    cnn_real, test_loader, device,\n",
        "    \"CNN treinada apenas com dados reais\"\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# TREINAMENTO DA cGAN CONVOLUCIONAL\n",
        "# =========================================================\n",
        "print(\"\\n=== TREINAMENTO DA cGAN CONVOLUCIONAL ===\")\n",
        "\n",
        "G = CGANGenerator(z_dim=z_dim).to(device)\n",
        "D = CGANDiscriminator().to(device)\n",
        "\n",
        "train_cgan(\n",
        "    G=G,\n",
        "    D=D,\n",
        "    dataloader=train_loader,\n",
        "    device=device,\n",
        "    epochs=30,\n",
        "    z_dim=z_dim\n",
        ")\n",
        "\n",
        "# =========================================================\n",
        "# FUNÇÃO: GERAR DADOS FAKE POR PROPORÇÃO\n",
        "# =========================================================\n",
        "def generate_fake_dataset_by_ratio(generator, ratio):\n",
        "    n_real = len(train_dataset)\n",
        "    n_fake = int(n_real * ratio)\n",
        "    n_per_class = n_fake // 10\n",
        "\n",
        "    images, labels = [], []\n",
        "\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        for cls in range(10):\n",
        "            z = torch.randn(n_per_class, z_dim, device=device)\n",
        "            y = torch.full((n_per_class,), cls, device=device, dtype=torch.long)\n",
        "            fake_imgs = generator(z, y)\n",
        "\n",
        "            images.append(fake_imgs.cpu())\n",
        "            labels.append(y.cpu())\n",
        "\n",
        "    images = torch.cat(images)\n",
        "    labels = torch.cat(labels)\n",
        "\n",
        "    return TensorDataset(images, labels)\n",
        "\n",
        "# =========================================================\n",
        "# FID — REAL × FAKE\n",
        "# =========================================================\n",
        "print(\"\\n=== FID (REAL × FAKE) ===\")\n",
        "\n",
        "real_features = extract_features(\n",
        "    model=cnn_real,\n",
        "    dataloader=train_loader,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "mu_real, sigma_real = compute_statistics(real_features)\n",
        "\n",
        "# =========================================================\n",
        "# LOOP DAS PROPORÇÕES\n",
        "# =========================================================\n",
        "for ratio in ratios:\n",
        "\n",
        "    print(f\"\\n=== PROPORÇÃO DE DADOS FAKE: {int(ratio*100)}% ===\")\n",
        "\n",
        "    # Dataset fake\n",
        "    fake_dataset = generate_fake_dataset_by_ratio(G, ratio)\n",
        "    fake_loader = DataLoader(\n",
        "        fake_dataset, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    # FID\n",
        "    fake_features = extract_features(\n",
        "        model=cnn_real,\n",
        "        dataloader=fake_loader,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    mu_fake, sigma_fake = compute_statistics(fake_features)\n",
        "\n",
        "    fid_value = calculate_fid(\n",
        "        mu_real, sigma_real, mu_fake, sigma_fake\n",
        "    )\n",
        "\n",
        "    print(f\"FID (Real vs Fake {int(ratio*100)}%): {fid_value:.2f}\")\n",
        "\n",
        "    # Dataset misto\n",
        "    mixed_dataset = ConcatDataset([train_dataset, fake_dataset])\n",
        "    mixed_loader = DataLoader(\n",
        "        mixed_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    # CNN treinada do zero\n",
        "    cnn_mixed = CNNClassifier().to(device)\n",
        "    train_cnn(cnn_mixed, mixed_loader, device, epochs=10)\n",
        "\n",
        "    # Avaliação SOMENTE com dados reais\n",
        "    plot_confusion_matrix(\n",
        "        cnn_mixed,\n",
        "        test_loader,\n",
        "        device,\n",
        "        f\"CNN com {int(ratio*100)}% dados sintéticos (cGAN Conv)\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "397lHc3lITvb",
        "outputId": "6f1bf1c2-2810-450b-89a2-136e0a43b11f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo: cpu\n",
            "\n",
            "=== CNN BASELINE (DADOS REAIS) ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2427914694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mcnn_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m plot_confusion_matrix(\n",
            "\u001b[0;32m/tmp/ipython-input-1361606162.py\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model, dataloader, device, epochs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoch+1}/{epochs}] | Loss: {loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 )\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##EVALUATION:\n",
        "\n",
        "#confusion_matriz.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def plot_confusion_matrix(model, dataloader, device, title):\n",
        "    \"\"\"\n",
        "    Calcula e plota a matriz de confusão de um classificador\n",
        "\n",
        "    Parâmetros:\n",
        "    - model: CNN treinada\n",
        "    - dataloader: loader do conjunto de teste\n",
        "    - device: cpu ou cuda\n",
        "    - title: título do gráfico\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # coloca o modelo em modo de avaliação\n",
        "\n",
        "    all_preds = []   # lista para armazenar predições\n",
        "    all_labels = []  # lista para armazenar rótulos reais\n",
        "\n",
        "    # Desativa cálculo de gradiente (economia de memória)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Classe predita = argmax dos logits\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # Armazena resultados\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    # Concatena todos os batches\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Calcula a matriz de confusão\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Cria objeto de visualização\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "\n",
        "    # Plota\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=True)\n",
        "    ax.set_title(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#fid.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "\n",
        "def extract_features(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extrai features intermediárias de uma CNN para cálculo do FID\n",
        "\n",
        "    Parâmetros:\n",
        "    - model: CNN treinada (usada como extrator)\n",
        "    - dataloader: DataLoader (real ou fake)\n",
        "    - device: cpu ou cuda\n",
        "\n",
        "    Retorno:\n",
        "    - features: array numpy (N, D)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()               # modo avaliação\n",
        "    features = []              # lista para armazenar features\n",
        "\n",
        "    with torch.no_grad():      # desativa gradientes\n",
        "        for images, _ in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Forward apenas até a camada convolucional\n",
        "            x = model.conv1(images)\n",
        "            x = torch.relu(x)\n",
        "            x = torch.max_pool2d(x, 2)\n",
        "\n",
        "            x = model.conv2(x)\n",
        "            x = torch.relu(x)\n",
        "            x = torch.max_pool2d(x, 2)\n",
        "\n",
        "            # Flatten das features\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "            features.append(x.cpu().numpy())\n",
        "\n",
        "    # Concatena todos os batches\n",
        "    features = np.concatenate(features, axis=0)\n",
        "    return features\n",
        "\n",
        "\n",
        "def compute_statistics(features):\n",
        "    \"\"\"\n",
        "    Calcula média e covariância das features\n",
        "\n",
        "    Parâmetros:\n",
        "    - features: array (N, D)\n",
        "\n",
        "    Retorno:\n",
        "    - mu: média (D,)\n",
        "    - sigma: covariância (D, D)\n",
        "    \"\"\"\n",
        "\n",
        "    mu = np.mean(features, axis=0)\n",
        "    sigma = np.cov(features, rowvar=False)\n",
        "\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
        "    \"\"\"\n",
        "    Calcula Fréchet Inception Distance (FID)\n",
        "\n",
        "    Fórmula:\n",
        "    ||μ1 - μ2||² + Tr(Σ1 + Σ2 - 2(Σ1Σ2)¹ᐟ²)\n",
        "    \"\"\"\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    # Produto das covariâncias\n",
        "    covmean, _ = linalg.sqrtm(sigma1 @ sigma2, disp=False)\n",
        "\n",
        "    # Correção numérica (parte imaginária pequena)\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid"
      ],
      "metadata": {
        "id": "zZIPF1oxHGly"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELS:\n",
        "\n",
        "#cgan_discriminator.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CGANDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminador convolucional condicional\n",
        "    Entrada: imagem + mapa de classe\n",
        "    Saída: probabilidade real/fake\n",
        "    \"\"\"\n",
        "    def __init__(self, n_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding do rótulo como mapa espacial\n",
        "        self.label_emb = nn.Embedding(n_classes, 28 * 28)\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(2, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128 * 7 * 7, 1)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # x: (B, 1, 28, 28)\n",
        "\n",
        "        y = self.label_emb(labels)               # (B, 784)\n",
        "        y = y.view(-1, 1, 28, 28)                # (B, 1, 28, 28)\n",
        "\n",
        "        x = torch.cat([x, y], dim=1)             # (B, 2, 28, 28)\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return torch.sigmoid(self.fc(x))\n",
        "\n",
        "#cgan_generator.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CGANGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    Gerador convolucional condicional (DC-cGAN)\n",
        "    Entrada: ruído z + rótulo y\n",
        "    Saída: imagem 1x28x28\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=100, n_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding do rótulo (one-hot projetado)\n",
        "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
        "\n",
        "        # Camada inicial totalmente conectada\n",
        "        self.fc = nn.Linear(z_dim + n_classes, 128 * 7 * 7)\n",
        "\n",
        "        # Blocos convolucionais transpostos\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 14x14\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1),    # 28x28\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        # z: (B, 100)\n",
        "        # labels: (B)\n",
        "\n",
        "        y = self.label_emb(labels)              # (B, 10)\n",
        "        x = torch.cat([z, y], dim=1)            # (B, 110)\n",
        "\n",
        "        x = self.fc(x)                          # (B, 128*7*7)\n",
        "        x = x.view(-1, 128, 7, 7)               # (B, 128, 7, 7)\n",
        "\n",
        "        return self.deconv(x)                   # (B, 1, 28, 28)\n",
        "\n",
        "\n",
        "#cnn.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN simples para classificação do MNIST\n",
        "    Entrada: imagem 1x28x28\n",
        "    Saída: logits para 10 classes\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Bloco convolucional 1\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        # Camadas totalmente conectadas\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Entrada: (B, 1, 28, 28)\n",
        "\n",
        "        x = F.relu(self.conv1(x))        # (B, 32, 28, 28)\n",
        "        x = F.max_pool2d(x, 2)           # (B, 32, 14, 14)\n",
        "\n",
        "        x = F.relu(self.conv2(x))        # (B, 64, 14, 14)\n",
        "        x = F.max_pool2d(x, 2)           # (B, 64, 7, 7)\n",
        "\n",
        "        x = x.view(x.size(0), -1)        # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)               # Logits"
      ],
      "metadata": {
        "id": "LzqmDmV-HQqQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING:\n",
        "\n",
        "#train_cgan.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_cgan(G, D, dataloader, device, epochs=30, z_dim=100):\n",
        "    \"\"\"\n",
        "    Treinamento padrão de uma DC-cGAN\n",
        "    \"\"\"\n",
        "    criterion = nn.BCELoss()\n",
        "    opt_g = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "    opt_d = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_imgs, labels in dataloader:\n",
        "            real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
        "            batch = real_imgs.size(0)\n",
        "\n",
        "            # Rótulos reais e falsos\n",
        "            valid = torch.ones(batch, 1, device=device)\n",
        "            fake = torch.zeros(batch, 1, device=device)\n",
        "\n",
        "            # ======================\n",
        "            # Treina Discriminador\n",
        "            # ======================\n",
        "            z = torch.randn(batch, z_dim, device=device)\n",
        "            gen_imgs = G(z, labels)\n",
        "\n",
        "            d_real = D(real_imgs, labels)\n",
        "            d_fake = D(gen_imgs.detach(), labels)\n",
        "\n",
        "            loss_d = criterion(d_real, valid) + criterion(d_fake, fake)\n",
        "\n",
        "            opt_d.zero_grad()\n",
        "            loss_d.backward()\n",
        "            opt_d.step()\n",
        "\n",
        "            # ======================\n",
        "            # Treina Gerador\n",
        "            # ======================\n",
        "            z = torch.randn(batch, z_dim, device=device)\n",
        "            gen_imgs = G(z, labels)\n",
        "\n",
        "            loss_g = criterion(D(gen_imgs, labels), valid)\n",
        "\n",
        "            opt_g.zero_grad()\n",
        "            loss_g.backward()\n",
        "            opt_g.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | D: {loss_d.item():.4f} | G: {loss_g.item():.4f}\")\n",
        "\n",
        "\n",
        "#train_cnn.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_cnn(model, dataloader, device, epochs=10):\n",
        "    \"\"\"\n",
        "    Treinamento supervisionado da CNN\n",
        "    \"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "nslZzTDQIJZ3"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}